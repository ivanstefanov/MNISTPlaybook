
1. Choose a real‚Äëworld dataset (e.g., tabular, image, or NLP) and train a PyTorch model.
---

## 1) –û—Ç–≤–æ—Ä–∏ Kubeflow UI

1. –í WSL –ø—É—Å–Ω–∏ port-forward (–∞–∫–æ –Ω–µ –µ –ø—É—Å–Ω–∞—Ç):

   ```bash
   export KUBECONFIG=/tmp/kubeflow-config
   kubectl port-forward svc/istio-ingressgateway -n istio-system 8080:80
   ```
2. –í Windows –±—Ä–∞—É–∑—ä—Ä: `http://localhost:8080`
3. –í–ª–µ–∑ —Å (–∞–∫–æ —Å–∏ –Ω–∞ default):

   * `user@example.com`
   * `12341234`

---

## 2) –°—ä–∑–¥–∞–π Notebook Server (UI)

1. –õ—è–≤–æ –º–µ–Ω—é ‚Üí **Notebooks** ‚Üí **+ New Notebook**
2. –ü—Ä–µ–ø–æ—Ä—ä—á–∏—Ç–µ–ª–Ω–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (–∑–∞ CPU —Ç—Ä–µ–Ω–∏–Ω–≥, –Ω–∞–ø—ä–ª–Ω–æ –¥–æ—Å—Ç–∞—Ç—ä—á–Ω–æ):

   * Image: –∏–∑–±–µ—Ä–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–µ–Ω Jupyter –æ–±—Ä–∞–∑ (–∞–∫–æ –∏–º–∞—à **PyTorch**-–æ–±—Ä–∞–∑ ‚Äî –æ—â–µ –ø–æ-–¥–æ–±—Ä–µ; –∞–∫–æ –Ω–µ, –ø–∞–∫ —Å—Ç–∞–≤–∞)
   * CPU: 2
   * RAM: 4‚Äì8 Gi
   * Workspace Volume: 10‚Äì20 Gi (PVC)
3. **Create** –∏ –∏–∑—á–∞–∫–∞–π —Å—Ç–∞—Ç—É—Å—ä—Ç –¥–∞ —Å—Ç–∞–Ω–µ **Running**, –ø–æ—Å–ª–µ **Connect**.

---

## 3) –í—ä—Ç—Ä–µ –≤ Jupyter: –∏–Ω—Å—Ç–∞–ª–∏—Ä–∞–π –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏

–û—Ç–≤–æ—Ä–∏ Terminal –≤ Jupyter (–∏–ª–∏ –∫–ª–µ—Ç–∫–∞ –≤ notebook) –∏ –∏–∑–ø—ä–ª–Ω–∏:

```bash
pip install -U pip
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
pip install pandas scikit-learn numpy
```

---

## 4) –†–µ–∞–ª–µ–Ω dataset + PyTorch –º–æ–¥–µ–ª (–≥–æ—Ç–æ–≤ notebook –∫–æ–¥)

–ù–∞–π-–ø—Ä–∞–∫—Ç–∏—á–Ω–æ –ø—Ä–µ–∑ UI –µ **tabular dataset** (—Ä–µ–∞–ª–Ω–∏ –¥–∞–Ω–Ω–∏, –±—ä—Ä–∑–æ). –î–∞–π —Å–∏ –Ω–æ–≤ Notebook: `adult_income.ipynb` –∏ –ø—É—Å–Ω–∏ —Å–ª–µ–¥–Ω–∏—Ç–µ –∫–ª–µ—Ç–∫–∏.

### –ö–ª–µ—Ç–∫–∞ 1 ‚Äî –∑–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ Adult Income (UCI)

```python
import numpy as np
import pandas as pd

TRAIN_URL = "https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data"
TEST_URL  = "https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test"

COLUMNS = [
    "age","workclass","fnlwgt","education","education-num","marital-status",
    "occupation","relationship","race","sex","capital-gain","capital-loss",
    "hours-per-week","native-country","income"
]

train = pd.read_csv(TRAIN_URL, header=None, names=COLUMNS, skipinitialspace=True)
test  = pd.read_csv(TEST_URL, header=0, names=COLUMNS, skipinitialspace=True, comment="|")
test["income"] = test["income"].str.replace(".", "", regex=False)

df = pd.concat([train, test], ignore_index=True)

for col in df.columns:
    df = df[df[col] != "?"]

df["income"] = (df["income"] == ">50K").astype(np.int64)

df.shape, df["income"].mean()
```

### –ö–ª–µ—Ç–∫–∞ 2 ‚Äî preprocessing (OneHot + StandardScaler)

```python
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.metrics import accuracy_score

y = df["income"].values
Xraw = df.drop(columns=["income"])

num_cols = Xraw.select_dtypes(include=["int64", "float64"]).columns.tolist()
cat_cols = [c for c in Xraw.columns if c not in num_cols]

pre = ColumnTransformer(
    transformers=[
        ("num", StandardScaler(), num_cols),
        ("cat", OneHotEncoder(handle_unknown="ignore"), cat_cols),
    ]
)

X_train_raw, X_val_raw, y_train, y_val = train_test_split(
    Xraw, y, test_size=0.2, random_state=42, stratify=y
)

X_train = pre.fit_transform(X_train_raw)
X_val = pre.transform(X_val_raw)

X_train = X_train.toarray() if hasattr(X_train, "toarray") else X_train
X_val = X_val.toarray() if hasattr(X_val, "toarray") else X_val

X_train.shape, X_val.shape
```

### –ö–ª–µ—Ç–∫–∞ 3 ‚Äî PyTorch Dataset + MLP

```python
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader

class AdultDataset(Dataset):
    def __init__(self, X, y):
        self.X = torch.tensor(X, dtype=torch.float32)
        self.y = torch.tensor(y, dtype=torch.long)

    def __len__(self):
        return self.X.shape[0]

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

class MLP(nn.Module):
    def __init__(self, in_features):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(in_features, 128),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(64, 2),
        )

    def forward(self, x):
        return self.net(x)

train_ds = AdultDataset(X_train, y_train)
val_ds = AdultDataset(X_val, y_val)

train_dl = DataLoader(train_ds, batch_size=256, shuffle=True)
val_dl = DataLoader(val_ds, batch_size=512)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = MLP(in_features=X_train.shape[1]).to(device)

opt = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)
loss_fn = nn.CrossEntropyLoss()

device
```

### –ö–ª–µ—Ç–∫–∞ 4 ‚Äî training loop + –º–µ—Ç—Ä–∏–∫–∏ + –∑–∞–ø–∏—Å –Ω–∞ –º–æ–¥–µ–ª

```python
import os

best_acc = 0.0
os.makedirs("artifacts", exist_ok=True)

for epoch in range(1, 11):
    model.train()
    for xb, yb in train_dl:
        xb, yb = xb.to(device), yb.to(device)
        opt.zero_grad()
        logits = model(xb)
        loss = loss_fn(logits, yb)
        loss.backward()
        opt.step()

    model.eval()
    preds, trues = [], []
    with torch.no_grad():
        for xb, yb in val_dl:
            xb = xb.to(device)
            logits = model(xb)
            p = torch.argmax(logits, dim=1).cpu().numpy()
            preds.append(p)
            trues.append(yb.numpy())

    acc = accuracy_score(np.concatenate(trues), np.concatenate(preds))
    print(f"Epoch {epoch:02d} | val_acc={acc:.4f}")

    if acc > best_acc:
        best_acc = acc
        torch.save(model.state_dict(), "artifacts/model.pt")

print("Best val_acc =", round(best_acc, 4))
print("Saved artifacts/model.pt")
```

---

## 5) –ö–∞–∫ –¥–∞ ‚Äú–ø–æ–∫–∞–∂–µ—à‚Äù, —á–µ –∑–∞–¥–∞—á–∞—Ç–∞ –µ –∏–∑–ø—ä–ª–Ω–µ–Ω–∞

–í UI –≤–µ—á–µ —â–µ –∏–º–∞—à:

* notebook —Å **—Ä–µ–∞–ª–µ–Ω dataset** (UCI Adult)
* –æ–±—É—á–µ–Ω PyTorch –º–æ–¥–µ–ª (MLP)
* –∏–∑–≤–µ–¥–µ–Ω–∏ –º–µ—Ç—Ä–∏–∫–∏ (val accuracy)
* –∞—Ä—Ç–µ—Ñ–∞–∫—Ç `artifacts/model.pt`

---
# Pipeline: Build a Kubeflow Pipeline with preprocessing, training, tuning, serving, monitoring, and retraining.

1) –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–∞–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∞—Ç–∞ –≤ PVC

–í —Ç–µ—Ä–º–∏–Ω–∞–ª–∞ –Ω–∞ notebook-–∞:

```sh
mkdir -p /home/jovyan/workspace/{data,processed,models,metrics,logs}
```

–ò –∑–∞–Ω–∞–ø—Ä–µ–¥:
- –¥–∞–Ω–Ω–∏ ‚Üí workspace/data
- –æ–±—Ä–∞–±–æ—Ç–µ–Ω–∏ ‚Üí workspace/processed
- –º–æ–¥–µ–ª–∏ ‚Üí workspace/models
- –º–µ—Ç—Ä–∏–∫–∏ ‚Üí workspace/metrics

–û—Ç–ª–∏—á–Ω–æ ‚Äî —Ç–æ–≤–∞ –µ **Kubeflow Pipelines v1 UI** (–∫–ª–∞—Å–∏—á–µ—Å–∫–∏—è—Ç –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å).
–ò–º–∞—à –±—É—Ç–æ–Ω **Upload pipeline**, –∫–æ–µ—Ç–æ –æ–∑–Ω–∞—á–∞–≤–∞:

> üéØ –ì–æ—Ç–æ–≤ —Å–∏ –¥–∞ –∫–∞—á–∏–º —Ä–µ–∞–ª–µ–Ω multi-step pipeline –∏ –¥–∞ –≥–æ —É–ø—Ä–∞–≤–ª—è–≤–∞–º–µ –∏–∑—Ü—è–ª–æ –ø—Ä–µ–∑ UI.

–°–µ–≥–∞ —â–µ —Ç–∏ –¥–∞–º **–º–∏–Ω–∏–º–∞–ª–µ–Ω, –Ω–æ –ø—ä–ª–µ–Ω MLOps pipeline**, –∫–æ–π—Ç–æ –ø–æ–∫—Ä–∏–≤–∞:

* preprocessing
* training
* evaluation
* tuning (Katib –æ—Ç–¥–µ–ª–Ω–æ)
* serving (KServe)
* monitoring
* retraining (Recurring Runs)

–©–µ –≥–æ –Ω–∞–ø—Ä–∞–≤–∏–º —Ç–∞–∫–∞, —á–µ –¥–∞ —Ä–∞–±–æ—Ç–∏ —Å —Ç–≤–æ—è PVC (`/home/jovyan`).

---

# üß† –°—Ç—ä–ø–∫–∞ 1 ‚Äî –ò–Ω—Å—Ç–∞–ª–∏—Ä–∞–π KFP SDK –≤ Notebook

–í notebook terminal:

```bash
pip install kfp==1.8.22
```

---

# üß† –°—Ç—ä–ø–∫–∞ 2 ‚Äî –°—ä–∑–¥–∞–π pipeline.py –≤ Notebook

–í–∏–∂  `train_pipeline.py` ....
pipeline-–∞ —Ä–∞–±–æ—Ç–∏ –∑–∞ –∑–∞ KFP v1, –∫–æ–π—Ç–æ:
- –Ω–µ –∏–∑–ø–æ–ª–∑–≤–∞ –≤—ä–Ω—à–Ω–∏ Docker images (—Å–∞–º–æ python:3.10)
- –Ω–µ —Ä–∞–∑—á–∏—Ç–∞ –Ω–∞ Docker Hub –∑–∞ PyTorch image
- –∏–Ω—Å—Ç–∞–ª–∏—Ä–∞ torch CPU –≤—ä—Ç—Ä–µ –≤ —Å—Ç—ä–ø–∫–∞—Ç–∞
- –∏–∑–ø–æ–ª–∑–≤–∞ –ø—Ä–∞–≤–∏–ª–Ω–æ InputPath / OutputPath
- –Ω–µ —á—É–ø–∏ artifact paths
- –Ω–µ –∏–∑–∏—Å–∫–≤–∞ PVC
- —Ä–∞–±–æ—Ç–∏ –≤ multi-user Kubeflow
- –∫–æ–º–ø–∏–ª–∏—Ä–∞ —Å kfp==1.8.x

---

# üß† –°—Ç—ä–ø–∫–∞ 3 ‚Äî –ö–æ–º–ø–∏–ª–∏—Ä–∞–π YAML

–í terminal:

```bash
python pipeline.py
```
(–∏–º–µ—Ç–æ –Ω–∞ —Ñ–∞–π–ª–∞ –∑–∞ –ø–∞–ø–π–ª–∞–π–Ω)
–©–µ —Å–µ —Å—ä–∑–¥–∞–¥–µ:

```
ml_pipeline.yaml
```
3.1. –°–ª–µ–¥ –∫–∞—Ç–æ —Å–µ —Å—ä–∑–¥–∞–¥–µ ml_pipeline.yaml, –≥–æ –æ—Ç–≤–æ—Ä–∏ –≤ notebook-a –∏ –≥–æ download –Ω–∞ –∫–æ–º–ø—é—Ç—ä—Ä–∞ –∑–∞ –ø–æ—Å–ª–µ–¥–≤–∞—â —ä–ø–ª–æ—É–¥.
---

# üß† –°—Ç—ä–ø–∫–∞ 4 ‚Äî –ö–∞—á–∏ –≥–æ –≤ UI

Pipelines ‚Üí **Upload pipeline**

* Name: `mlops-adult`
* File: `ml_pipeline.yaml` //–∏–º–µ—Ç–æ –Ω–∞ —Ñ–∞–π–ª–∞ –µ –∑–∞–ø–∏—Å–∞–Ω–æ –≤ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞
* Upload

---

# –°—Ç—ä–ø–∫–∞ 4.1 - –°—ä–∑–¥–∞–π –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç

1. –í –ª—è–≤–æ—Ç–æ –º–µ–Ω—é –ø–æ–¥ Pipelines –Ω–∞—Ç–∏—Å–Ω–∏ Experiments (–∏–ª–∏ —Å–ª–µ–¥ —Å—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞)
2. –ù–∞—Ç–∏—Å–Ω–∏ + New experiment
3. –ò–º–µ, –Ω–∞–ø—Ä. `adult-income-exp`
4. Create
–ü–æ—Å–ª–µ:
5. –û—Ç–∏–¥–∏ –ø–∞–∫ –Ω–∞ Pipelines ‚Üí –∏–∑–±–µ—Ä–∏ –∫–∞—á–µ–Ω–∏—è pipeline
6. –ù–∞—Ç–∏—Å–Ω–∏ Create run (–∏–ª–∏ + Run)
7. –í –ø–æ–ª–µ—Ç–æ Experiment –∏–∑–±–µ—Ä–∏ adult-income-exp
8. Create/Start

# üß† –°—Ç—ä–ø–∫–∞ 5 ‚Äî –°—ä–∑–¥–∞–π Run

–°–ª–µ–¥ upload:

* Create Run
* Start

–©–µ –≤–∏–¥–∏—à graph:

```
Preprocess ‚Üí Train ‚Üí Evaluate
```

–ò accuracy —â–µ —Å–µ –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä–∞ –∫–∞—Ç–æ metric.

---
–û—Ç–ª–∏—á–Ω–æ.
–°–µ–≥–∞ –≤–µ—á–µ —Å–º–µ –Ω–∞ —Å—Ç–∞–±–∏–ª–Ω–∞ –æ—Å–Ω–æ–≤–∞ –∏ –º–æ–∂–µ–º –¥–∞ –Ω–∞–ø—Ä–∞–≤–∏–º **Katib tuning –ø—Ä–µ–∑ UI**, –±–µ–∑ –¥–∞ —á—É–ø–∏–º –Ω–∏—â–æ.

–©–µ –∏–∑–ø–æ–ª–∑–≤–∞–º–µ —Å—ä—â–∞—Ç–∞ –ª–æ–≥–∏–∫–∞ –∫–∞—Ç–æ –≤ pipeline-–∞, –Ω–æ Katib —â–µ –ø—É—Å–∫–∞ training job-–∏ —Å —Ä–∞–∑–ª–∏—á–Ω–∏ `lr` –∏ `epochs`.

---

# üéØ –¶–µ–ª

–î–∞ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–∞–º–µ:

* `lr`
* `epochs`

–∑–∞ –º–µ—Ç—Ä–∏–∫–∞—Ç–∞:

```
accuracy
```

---

# üß† –í–∞–∂–Ω–æ: Katib –Ω–µ —Å—Ç–∞—Ä—Ç–∏—Ä–∞ pipeline

Katib —Å—Ç–∞—Ä—Ç–∏—Ä–∞ **Kubernetes Job**, –Ω–µ KFP pipeline.

–ó–∞—Ç–æ–≤–∞ —â–µ —Å—ä–∑–¥–∞–¥–µ–º –æ—Ç–¥–µ–ª–µ–Ω training entrypoint –∑–∞ Katib, –∫–æ–π—Ç–æ:

* –ø—Ä–∏–µ–º–∞ –∞—Ä–≥—É–º–µ–Ω—Ç–∏
* —Ç—Ä–µ–Ω–∏—Ä–∞
* –æ—Ç–ø–µ—á–∞—Ç–≤–∞ `accuracy=<value>`

---

# ‚úÖ –°—Ç—ä–ø–∫–∞ 1 ‚Äì –°—ä–∑–¥–∞–π katib_train.py

–í Notebook —Å—ä–∑–¥–∞–π —Ñ–∞–π–ª `katib_train.py` (—Ç–µ–∫—Å—Ç–∞ –µ –∑–∞–ø–∞–∑–µ–Ω –≤ —Ç–∞–∑–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è)


–ü—Ä–æ–≤–µ—Ä–∏ –ª–æ–∫–∞–ª–Ω–æ:

```bash
python katib_train.py --lr 0.01 --epochs 30
```

–¢—Ä—è–±–≤–∞ –¥–∞ –≤–∏–¥–∏—à:
```
accuracy=0.9...
```
---

# üöÄ –°—Ç—ä–ø–∫–∞ 2 ‚Äì –°—ä–∑–¥–∞–π Katib Experiment (UI)

UI ‚Üí **Katib Experiments** ‚Üí **New Experim–î–æ–ª—É –Ω–∞—Ç–∏—Å–Ω–∏ –¥–∞ —Ä–µ–¥–∞–∫—Ç–∏—Ä–∞—à YAML-a –∏ paste —Å—ä–¥—ä—Ä–∂–∞–Ω–∏–µ—Ç–æ –Ω–∞ `katlib_experiment.yaml`
## –ö–∞–∫ –¥–∞ –≥–æ –ø—Ä–∏–ª–æ–∂–∏—à –ø—Ä–µ–∑ UI

1. Katib Experiments ‚Üí Create Experiment (–∏–ª–∏ —Å—ä–∑–¥–∞–π –ø—Ä–∞–∑–µ–Ω –∏ –ø–æ—Å–ª–µ Edit YAML)
2. –û—Ç–≤–æ—Ä–∏ YAML editor –∑–∞ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
3. Paste —Ç–æ–∑–∏ YAML
4. Save / Apply

## –ö–∞–∫ –¥–∞ –ø—Ä–æ–≤–µ—Ä–∏—à, —á–µ —Ä–∞–±–æ—Ç–∏

1. –í Katib experiment-–∞ —Ç—Ä—è–±–≤–∞ –¥–∞ —Å–µ –ø–æ—è–≤—è—Ç trials
2. –í trials —â–µ –∏–º–∞ Jobs –≤ namespace kubeflow-user-example-com
3. –°–ª–µ–¥ 1‚Äì2 trial-–∞ —Ç—Ä—è–±–≤–∞ –¥–∞ –≤–∏–¥–∏—à accuracy –æ—Ç—á–µ—Ç–µ–Ω–æ